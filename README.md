## Liberando Productos - Pr√°ctica Final.
Este proyecto es una API desarrollada con FastAPI y desplegada en Kubernetes, monitorizada con Prometheus + Alertmanager + Grafana, e integrada con un pipeline de CI/CD usando GitHub Actions.
Incluye pruebas automatizadas, m√©tricas personalizadas, alertas configuradas y un dashboard completo para visualizaci√≥n.


 ## √çndice
- C√≥digo para el nuevo endpoint y tests unitario

- CI/CD (GitHub Actions)
  
- Construcci√≥n de la imagen Docker
  
- Despliegue y monitorizaci√≥n
  
- Dashboard Grafana (JSON)
  
- Estructura del proyecto
  
- C√≥mo reproducir paso a paso



## C√≥digo para el nuevo endpoint y tests unitario.

- La app est√° escrita con FastAPI y expone varios endpoints (/, /bye, /health, /metrics).

- Se han a√±adido m√©tricas personalizadas con prometheus_client:

- main_requests_total, bye_requests_total, healthcheck_requests_total, fastapi_app_starts_total

- Incluye tests con Pytest y cobertura:

üìÇ Ver c√≥digo en: src/ https://github.com/RAMON1743/liberando-productos-practica-ramon-meza/tree/main/src/application
imgen endpoint

üìÇ Ver tests en: tests/ https://github.com/RAMON1743/liberando-productos-practica-ramon-meza/tree/main/src/tests

imagen del test unitario pasado

## CI/CD (GitHub Actions)

Workflows definidos:

### Testing: github/workflows/test.yaml
Este workflow se ejecuta autom√°ticamente en cada push o pull request sobre ramas como main o develop. 

Su funci√≥n es:
- Ejecutar tests unitarios de la aplicaci√≥n (usando pytest).
- Generar un informe de cobertura de c√≥digo.
- Validar que el c√≥digo subido cumple con los est√°ndares.
  
üìÇ Ver c√≥digo en: test/ [c√≥digo de tests](./.github/workflows/test.yaml)


### Build & Push (Release): github/workflows/release.yaml
Este segundo workflow se ejecuta autom√°ticamente cuando se crea un tag con formato vX.X.X (por ejemplo: v3.0.0). Sus pasos:
- Construye una imagen Docker de la aplicaci√≥n.
- La empaqueta con la versi√≥n correspondiente (:3.0.0).
- La sube a DockerHub usando las credenciales almacenadas como secrets del repositorio.
Los secrets utilizados para autenticaci√≥n son:
DOCKERHUB_USERNAME
DOCKERHUB_TOKEN
Para lanzar este workflow, simplemente se corre:
```sh
git tag v3.0.0
git push origin v3.0.0
```
üìÇ Ver c√≥digo en: Release/ [c√≥digo release](./.github/workflows/release.yaml)

imagen action 

- La imagen se publica como: (**docker.io/ramon1743/liberando-productos-practica-final-ramon-meza:3.0.0)**


imagen Dockerhub


**Esta implementaci√≥n cumple con los requisitos de:**
- Pruebas autom√°ticas con cobertura (Testing)
- Build & Push de imagen Docker (Release)
- Uso de GitHub Actions como plataforma de CI/CD
- Uso de tags para gestionar releases
- Publicaci√≥n en un registry v√°lido (DockerHub)



## Construcci√≥n de la imagen Docker

**Construir la imagen**

```sh
docker build -t ramon1743/simple-server:0.0.2 
```

Esto genera una imagen Docker etiquetada como simple-server:0.0.2 basada en el Dockerfile del proyecto.



Subimo la imagen a DockerHu

```sh
docker push ramon1743/simple-server:0.0.2
```

**Este paso requiere que est√©s logueado previamente en DockerHub:**

```sh
docker login
```

**Probamos localmente la imagen Docker**

```sh
docker run -d -p 8000:8000 -p 8081:8081 --name simple-server ramon1743/simple-server:0.0.2

```

Permite lenvantar la app en segundo plano con los puertos necesarios para acceder a los endpoints (/) y a las m√©tricas Prometheus (/metrics).

## Despliegue y Monitorizaci√≥n
Se ha desplegado un entorno completo de observabilidad y monitorizaci√≥n basado en Prometheus y Grafana, cumpliendo con los requisitos de la pr√°ctica. Tambi√©n se ha realizado el despliegue de la aplicaci√≥n en Kubernetes y se han integrado m√©tricas personalizadas y alertas.


## Prometheus + Grafana desplegados con Helm
Se ha utilizado el chart kube-prometheus-stack para instalar Prometheus, Grafana, y los componentes relacionados:


```sh
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update

helm install monitoring prometheus-community/kube-prometheus-stack \
  -f helm-values/kube-state-values.yaml \
  -f helm-values/alertmanager-config.yaml \
  -f helm-values/additional-rules.yaml \
  -f helm-values/prometheus-persistence.yaml
```


**Los valores definidos permiten:**
- Configurar el acceso y scraping de m√©tricas del cluster.
- Incluir reglas de alerta personalizadas.
- Integrar alertas con Slack.
- Habilitar persistencia para Prometheus.

## Despliegue de la Aplicaci√≥n
La aplicaci√≥n FastAPI ha sido desplegada en Kubernetes con los siguientes manifiestos:

```bash

kubectl apply -f k8s/deployment.yaml
kubectl apply -f k8s/service.yaml
kubectl apply -f k8s/fastapi-servicemonitor.yaml

```

**Esto asegura que:**
- La app se ejecuta como un Deployment.
- Se expone v√≠a un Service.
- Est√° registrada ante Prometheus mediante un ServiceMonitor.

Esto cumple con el despliegue completo de la app + monitorizaci√≥n Prometheus a trav√©s de ServiceMonitor.


## M√©tricas personalizadas disponibles

La aplicaci√≥n expone m√©tricas personalizadas accesibles en el endpoint /metrics, incluyendo:

- main_requests_total: n√∫mero de llamadas al endpoint principal.
- healthcheck_requests_total: n√∫mero de llamadas al endpoint del estado de la app.
- bye_requests_total: n√∫mero de llamadas al endpoint de despedida.
- fastapi_app_starts_total: n√∫mero de veces que la app ha arrancado.

Cumple con el requisito de tener m√©tricas personalizadas √∫tiles para monitorizaci√≥n y alertas.



## Reglas de alerta personalizadas

Se han definido reglas en helm-values/additional-rules.yaml, como por ejemplo:

- CPU > 80% durante m√°s de 1 minuto, lo cual permite detectar sobrecarga.

Para probarlas, se puede simular carga con:

```bash
kubectl apply -f k8s/cpu-test-app.yaml
```


## Integraci√≥n de Alertas con Slack
Las alertas se integran con Slack mediante un **webhook configurado en alertmanager-config.yaml**. Esto permite notificar a un canal espec√≠fico cuando se cumple una regla.
-Se crear el Webhook de Slack
-Se cre√≥ una app de Slack y se activ√≥ la opci√≥n de Incoming Webhooks.
-Se gener√≥ un webhook para el canal #ramon-prometheus-alarms.
-Con la url obtenida: 'https://hooks.slack.com/services/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'
-Se agrega la configuraci√≥n del webhook en helm-values/alertmanager-config.yaml.
-Esto permite que todas las alertas activas y resueltas lleguen directamente a #ramon-prometheus-alarms



**imagen de las alerta slack****



## Desplegar con Helm
La configuraci√≥n se aplica al instalar o actualizar Prometheus con:

```bash

helm upgrade --install monitoring prometheus-community/kube-prometheus-stack \
  -f helm-values/alertmanager-config.yaml \
  -f helm-values/additional-rules.yaml \
  -f [...otros archivos...]
```


## Probar las alertas

Se puede simular una alerta (por ejemplo de alto uso de CPU) aplicando:

```bash

kubectl apply -f k8s/cpu-test-app.yaml

```


**Acceso v√≠a navegador**

Est√° expuesto en el cl√∫ster de Kubernetes en el puerto 9090, por lo tanto, puedes acceder desde tu navegador con:

```bash
http://localhost:9090
```



**Imagen de prometheus**



**Resultado**
Cada vez que se cumpla una condici√≥n de alerta:
- Slack recibe una notificaci√≥n clara y estructurada en el canal #ramon-prometheus-alarms.
- As√≠ nos actuar de forma inmediata ante problemas de infraestructura o aplicaci√≥n.



## Dashboard de Grafana 
Se ha creado un dashboard desde cero en Grafana, el cual muestra:

- N√∫mero de llamadas a los endpoints.

- N√∫mero de veces que la aplicaci√≥n ha arrancado.

Archivo JSON [Archivo Json](https://fastapi.tiangolo.com/)



**Acceso a Grafana**

Grafana est√° expuesto en el cl√∫ster de Kubernetes en el puerto 30000, por lo tanto, puedes acceder desde tu navegador con:



```bash
http://localhost:3000
```



**Login Grafana**


- Usuario: **admin**

- Contrase√±a: **prom-operator**




## Estructura del proyecto


```bash

LIBERANDO-PRODUCTOS-PRACTICA-RAMON-MEZA/
‚îú‚îÄ‚îÄ .github/                        # Workflows de CI/CD
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îú‚îÄ‚îÄ release.yaml
‚îÇ       ‚îî‚îÄ‚îÄ test.yaml
‚îú‚îÄ‚îÄ .pytest_cache/
‚îÇ   ‚îú‚îÄ‚îÄ v/
‚îÇ   ‚îú‚îÄ‚îÄ .gitignore
‚îÇ   ‚îî‚îÄ‚îÄ CACHEDIR.TAG
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ helm-values/                     # Configuraci√≥n para Prometheus stack
‚îÇ   ‚îú‚îÄ‚îÄ additional-rules.yaml
‚îÇ   ‚îú‚îÄ‚îÄ alertmanager-config.yaml
‚îÇ   ‚îú‚îÄ‚îÄ alertmanager-secret.yaml
‚îÇ   ‚îú‚îÄ‚îÄ kube-state-values.yaml
‚îÇ   ‚îî‚îÄ‚îÄ prometheus-persistence.yaml
‚îú‚îÄ‚îÄ htmlcov/
‚îú‚îÄ‚îÄ k8s/                            # Manifiestos de Kubernetes
‚îÇ   ‚îú‚îÄ‚îÄ cpu-test-app.yaml
‚îÇ   ‚îú‚îÄ‚îÄ deployment.yaml
‚îÇ   ‚îú‚îÄ‚îÄ fastapi-servicemonitor.yaml
‚îÇ   ‚îî‚îÄ‚îÄ service.yaml
‚îú‚îÄ‚îÄ src/                            # C√≥digo fuente de la app
‚îú‚îÄ‚îÄ venv/
‚îú‚îÄ‚îÄ .coverage
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ grafana-fastapi-dashboard.json  # Dashboard exportado a JSON
‚îú‚îÄ‚îÄ Makefile
‚îú‚îÄ‚îÄ pytest.ini
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ requirements.txt

```



## C√≥mo reproducir paso a paso


**Clona el repo y entra en la carpeta:**

```bash

git clone git@github.com:RAMON1743/liberando-productos-practica-ramon-meza.git

```

**Iniciamos el cluster Minikube:**

```bash
minikube start --cpus=4 --memory=6g --disk-size=20g

```


**Habilita addons:**

```bash
minikube addons enable metrics-server
minikube addons enable ingress

```

## Validar que todo est√° funcionando correctamente

**Verificar pods**

```bash
kubectl get pods
```

**Validar de que todos los pods est√©n en estado Running, tanto de la app como del stack monitoring.**

**Verificar servicios**

```bash
kubectl get svc
```

**Confirma que existen y est√°n expuestos los servicios:**

- Monitoring-grafana
- Monitoring-prometheus
- Monitoring-alertmanager
- Fastapi

  
**Verificar targets en Prometheus**

En Prometheus (una vez abierto), ve a Status > Targets y revisa que tu ServiceMonitor est√© UP.


## Acceder a los servicios v√≠a navegador

```bash
kubectl port-forward svc/monitoring-grafana 3000:80
kubectl port-forward svc/monitoring-kube-prometheus-prometheus 9090
kubectl port-forward svc/monitoring-kube-prometheus-alertmanager 9093

```


**Accede en el navegador:**

- **Grafana**: http://localhost:3000

- **Prometheus**: http://localhost:9090

- **Alertmanager**: http://localhost:9093












El proyecto inicial es un servidor que realiza lo siguiente:

- Utiliza [FastAPI](https://fastapi.tiangolo.com/) para levantar un servidor en el puerto `8081` e implementa inicialmente dos endpoints:
  - `/`: Devuelve en formato `JSON` como respuesta `{"health": "ok"}` y un status code 200.
  - `/health`: Devuelve en formato `JSON` como respuesta `{"message":"Hello World"}` y un status code 200.

- Se han implementado tests unitarios para el servidor [FastAPI](https://fastapi.tiangolo.com/)

- Utiliza [prometheus-client](https://github.com/prometheus/client_python) para arrancar un servidor de m√©tricas en el puerto `8000` y poder registrar m√©tricas, siendo inicialmente las siguientes:
  - `Counter('server_requests_total', 'Total number of requests to this webserver')`: Contador que se incrementar√° cada vez que se haga una llamada a alguno de los endpoints implementados por el servidor (inicialmente `/` y `/health`)
  - `Counter('healthcheck_requests_total', 'Total number of requests to healthcheck')`: Contador que se incrementar√° cada vez que se haga una llamada al endpoint `/health`.
  - `Counter('main_requests_total', 'Total number of requests to main endpoint')`: Contador que se incrementar√° cada vez que se haga una llamada al endpoint `/`.

## Software necesario

Es necesario disponer del siguiente software:

- `Python` en versi√≥n `3.11.8` o superior, disponible para los diferentes sistemas operativos en la [p√°gina oficial de descargas](https://www.python.org/downloads/release/python-3118/)

- `virtualenv` para poder instalar las librer√≠as necesarias de Python, se puede instalar a trav√©s del siguiente comando:

    ```sh
    pip3 install virtualenv
    ```

    En caso de estar utilizando Linux y el comando anterior diera fallos se debe ejecutar el siguiente comando:

    ```sh
    sudo apt-get update && sudo apt-get install -y python3.11-venv
    ```

- `Docker` para poder arrancar el servidor implementado a trav√©s de un contenedor Docker, es posible descargarlo a [trav√©s de su p√°gina oficial](https://docs.docker.com/get-docker/).

## Ejecuci√≥n de servidor

### Ejecuci√≥n directa con Python

1. Instalaci√≥n de un virtualenv, **realizarlo s√≥lo en caso de no haberlo realizado previamente**:
   1. Obtener la versi√≥n actual de Python instalada para crear posteriormente un virtualenv:

        ```sh
        python3 --version
        ```

        El comando anterior mostrar√° algo como lo mostrado a continuaci√≥n:√ß

        ```sh
        Python 3.11.8
        ```

   2. Crear de virtualenv en la ra√≠z del directorio para poder instalar las librer√≠as necesarias:

      ```sh
      python3 -m venv venv
      ```

2. Activar el virtualenv creado en el directorio `venv` en el paso anterior:

     ```sh
     source venv/bin/activate
     ```

3. Instalar las librer√≠as necesarias de Python, recogidas en el fichero `requirements.txt`, **s√≥lo en caso de no haber realizado este paso previamente**. Es posible instalarlas a trav√©s del siguiente comando:

    ```sh
    pip3 install -r requirements.txt
    ```

4. Ejecuci√≥n del c√≥digo para arrancar el servidor:

    ```sh
    python3 src/app.py
    ```

5. La ejecuci√≥n del comando anterior deber√≠a mostrar algo como lo siguiente:

    ```sh
    [2022-04-16 09:44:22 +0000] [1] [INFO] Running on http://0.0.0.0:8081 (CTRL + C to quit)
    ```

### Ejecuci√≥n a trav√©s de un contenedor Docker

1. Crear una imagen Docker con el c√≥digo necesario para arrancar el servidor:

    ```sh
    docker build -t simple-server:0.0.1 .
    ```

2. Arrancar la imagen construida en el paso anterior mapeando los puertos utilizados por el servidor de FastAPI y el cliente de prometheus:

    ```sh
    docker run -d -p 8000:8000 -p 8081:8081 --name simple-server simple-server:0.0.1
    ```

3. Obtener los logs del contenedor creado en el paso anterior:

    ```sh
    docker logs -f simple-server
    ```

4. La ejecuci√≥n del comando anterior deber√≠a mostrar algo como lo siguiente:

    ```sh
    [2022-04-16 09:44:22 +0000] [1] [INFO] Running on http://0.0.0.0:8081 (CTRL + C to quit)
    ```

## Comprobaci√≥n de endpoints de servidor y m√©tricas

Una vez arrancado el servidor, utilizando cualquier de las formas expuestas en los apartados anteriores, es posible probar las funcionalidades implementadas por el servidor:

- Comprobaci√≥n de servidor FastAPI, a trav√©s de llamadas a los diferentes endpoints:

  - Realizar una petici√≥n al endpoint `/`

      ```sh
      curl -X 'GET' \
      'http://0.0.0.0:8081/' \
      -H 'accept: application/json'
      ```

      Deber√≠a devolver la siguiente respuesta:

      ```json
      {"message":"Hello World"}
      ```

  - Realizar una petici√≥n al endpoint `/health`

      ```sh
      curl -X 'GET' \
      'http://0.0.0.0:8081/health' \
      -H 'accept: application/json' -v
      ```

      Deber√≠a devolver la siguiente respuesta.

      ```json
      {"health": "ok"}
      ```

- Comprobaci√≥n de registro de m√©tricas, si se accede a la URL `http://0.0.0.0:8000` se podr√°n ver todas las m√©tricas con los valores actuales en ese momento:

  - Realizar varias llamadas al endpoint `/` y ver como el contador utilizado para registrar las llamadas a ese endpoint, `main_requests_total` ha aumentado, se deber√≠a ver algo como lo mostrado a continuaci√≥n:

    ```sh
    # TYPE main_requests_total counter
    main_requests_total 4.0
    ```

  - Realizar varias llamadas al endpoint `/health` y ver como el contador utilizado para registrar las llamadas a ese endpoint, `healthcheck_requests_total` ha aumentado, se deber√≠a ver algo como lo mostrado a continuaci√≥n:

    ```sh
    # TYPE healthcheck_requests_total counter
    healthcheck_requests_total 26.0
    ```

  - Tambi√©n se ha credo un contador para el n√∫mero total de llamadas al servidor `server_requests_total`, por lo que este valor deber√≠a ser la suma de los dos anteriores, tal y como se puede ver a continuaci√≥n:

    ```sh
    # TYPE server_requests_total counter
    server_requests_total 30.0
    ```

## Tests

Se ha implementado tests unitarios para probar el servidor FastAPI, estos est√°n disponibles en el archivo `src/tests/app_test.py`.

Es posible ejecutar los tests de diferentes formas:

- Ejecuci√≥n de todos los tests:

    ```sh
    pytest
    ```

- Ejecuci√≥n de todos los tests y mostrar cobertura:

    ```sh
    pytest --cov
    ```

- Ejecuci√≥n de todos los tests y generaci√≥n de report de cobertura:

    ```sh
    pytest --cov --cov-report=html
    ```

## Practica a realizar

A partir del ejemplo inicial descrito en los apartados anteriores es necesario realizar una serie de mejoras:

Los requirimientos son los siguientes:

- A√±adir por lo menos un nuevo endpoint a los existentes `/` y `/health`, un ejemplo ser√≠a `/bye` que devolver√≠a `{"msg": "Bye Bye"}`, para ello ser√° necesario a√±adirlo en el fichero [src/application/app.py](./src/application/app.py)

- Creaci√≥n de tests unitarios para el nuevo endpoint a√±adido, para ello ser√° necesario modificar el [fichero de tests](./src/tests/app_test.py)

- Opcionalmente creaci√≥n de helm chart para desplegar la aplicaci√≥n en Kubernetes, se dispone de un ejemplo de ello en el laboratorio realizado en la clase 3

- Creaci√≥n de pipelines de CI/CD en cualquier plataforma (Github Actions, Jenkins, etc) que cuenten por lo menos con las siguientes fases:

  - Testing: tests unitarios con cobertura. Se dispone de un [ejemplo con Github Actions en el repositorio actual](./.github/workflows/test.yaml)

  - Build & Push: creaci√≥n de imagen docker y push de la misma a cualquier registry v√°lido que utilice alguna estrategia de release para los tags de las vistas en clase, se recomienda GHCR ya incluido en los repositorios de Github. Se dispone de un [ejemplo con Github Actions en el repositorio actual](./.github/workflows/release.yaml)

- Configuraci√≥n de monitorizaci√≥n y alertas:

  - Configurar monitorizaci√≥n mediante prometheus en los nuevos endpoints a√±adidos, por lo menos con la siguiente configuraci√≥n:
    - Contador cada vez que se pasa por el/los nuevo/s endpoint/s, tal y como se ha realizado para los endpoints implementados inicialmente

  - Desplegar prometheus a trav√©s de Kubernetes mediante minikube y configurar alert-manager para por lo menos las siguientes alarmas, tal y como se ha realizado en el laboratorio del d√≠a 3 mediante el chart `kube-prometheus-stack`:
    - Uso de CPU de un contenedor mayor al del l√≠mite configurado, se puede utilizar como base el ejemplo utilizado en el laboratorio 3 para mandar alarmas cuando el contenedor de la aplicaci√≥n `fast-api` consum√≠a m√°s del asignado mediante request

  - Las alarmas configuradas deber√°n tener severity high o critical

  - Crear canal en slack `<nombreAlumno>-prometheus-alarms` y configurar webhook entrante para env√≠o de alertas con alert manager

  - Alert manager estar√° configurado para lo siguiente:
    - Mandar un mensaje a Slack en el canal configurado en el paso anterior con las alertas con label "severity" y "critical"
    - Deber√°n enviarse tanto alarmas como recuperaci√≥n de las mismas
    - Habr√° una plantilla configurada para el env√≠o de alarmas

    Para poder comprobar si esta parte funciona se recomienda realizar una prueba de estres, como la realizada en el laboratorio 3 a partir del paso 8.

  - Creaci√≥n de un dashboard de Grafana, con por lo menos lo siguiente:
    - N√∫mero de llamadas a los endpoints
    - N√∫mero de veces que la aplicaci√≥n ha arrancado

## Entregables

Se deber√° entregar mediante un repositorio realizado a partir del original lo siguiente:

- C√≥digo de la aplicaci√≥n y los tests modificados
- Ficheros para CI/CD configurados y ejemplos de ejecuci√≥n v√°lidos
- Ficheros para despliegue y configuraci√≥n de prometheus de todo lo relacionado con este, as√≠ como el dashboard creado exportado a `JSON` para poder reproducirlo
- `README.md` donde se explique como se ha abordado cada uno de los puntos requeridos en el apartado anterior, con ejemplos pr√°cticos y gu√≠a para poder reproducir cada uno de ellos
